{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import plotly.express as px\n",
    "import dataframe_image as dfi\n",
    "\n",
    "from Project1 import *\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Boston Airbnb Dataset\n",
    "https://www.kaggle.com/datasets/airbnb/boston?resource=download\n",
    "\n",
    "CRISP-DM:\n",
    "- Business understanding: cusomters of Airbnb - hosts and guests - ultimately need to converge on price. What factors influence prices?\n",
    "    - **Price** is our dependent variable.\n",
    "    - We'll explore the dataset to determine our **independent variables** (predictors for a model).\n",
    "- Data understanding: Given raw data from Kaggle, what variables in the dataset can be used to predict price?\n",
    "- Data preparation: evaluate the data by type, look for what can be used for a parsimonious model, fill missing data where possible, exclude data where justifiable.\n",
    "    - Use visualizations, aggregation, filtering to better understand and prepare the data.\n",
    "- Data modeling: select an appropriate algorithm to model price given selected predcitors.\n",
    "    - Algo should be robust to missing values, and not senstive to potential correlation among the independent variables.\n",
    "    - Algo should be able to utilize both numeric and categorical values among the independent variables.\n",
    "- Result evaluation: train a model and evaluate the fit.\n",
    "- Deployment: predict prices using test (out of sample) data and summarize findings in a post on Medium.\n",
    "\n",
    "Three questions/topics to explore:\n",
    "- How does **geography** inlfuence Airbnb **prices** in Boston?\n",
    "    - What areas/zip codes/neighborhoods are more expensive than others?\n",
    "- How do **property characteristics** influence Airbnb prices in Boston?\n",
    "    - Number of bathrooms, bedrooms, beds, square footage, reviews, etc.\n",
    "- How does **time (seasonality)** influence Airbnb prices in Boston?\n",
    "    - Period of the week (days), period of the month (weeks), period of the year (months)?\n",
    "    - We only have about 2 years of data to work with, but we'll see what comes out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# First, load and clean the data\n",
    "- I did not ultimately use *monthly_price*/*weekly_price* in the model, but I used OLS to estimate the missing values based on *price*.\n",
    "- I used a KNN classifier to fill in missing zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listings = pd.read_csv('./data/airbnb_boston/listings.csv', index_col='id')\n",
    "boston_calendar = pd.read_csv('./data/airbnb_boston/calendar.csv')\n",
    "boston_reviews = pd.read_csv('./data/airbnb_boston/reviews.csv')\n",
    "\n",
    "boston_listings = boston_listings.map(convert_dollars_to_float).map(convert_percentages_to_float).map(convert_string_date_to_dt)\n",
    "boston_calendar = boston_calendar.apply(convert_dollars_to_float).map(convert_percentages_to_float).map(convert_string_date_to_dt)\n",
    "boston_reviews = boston_reviews.apply(convert_dollars_to_float).map(convert_percentages_to_float).map(convert_string_date_to_dt)\n",
    "\n",
    "# estimate missing monthly_price/weekly_price fields using regression (based on price field)\n",
    "boston_listings = estimate_y_from_X_ols(\n",
    "    data=boston_listings, y_label='monthly_price', X_labels='price')['filled_data']\n",
    "boston_listings = estimate_y_from_X_ols(\n",
    "    data=boston_listings, y_label='weekly_price', X_labels='price')['filled_data']\n",
    "\n",
    "# estimate missing zip codes using KNN classification (based on latitude and longitude)\n",
    "boston_listings = classify_y_based_on_X_knn(\n",
    "    data=get_cleaned_zipcodes(boston_listings), y_label='zipcode_cleaned', X_labels=['latitude', 'longitude'])['filled_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify column types\n",
    "boston_listing_col_types = get_columns_and_types(boston_listings)\n",
    "boston_calendar_col_types = get_columns_and_types(boston_calendar)\n",
    "boston_review_col_types = get_columns_and_types(boston_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Are there outliers in *price*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_cutoff = 500\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 3))\n",
    "boston_listings['price'].plot.hist(\n",
    "    title='Distribution of All Prices', ax=axes[0]);\n",
    "boston_listings['price'].sort_values(ascending=False).head(100).plot.hist(\n",
    "    title='Distribution of Largest 100 Prices', ax=axes[1]);\n",
    "boston_listings['price'].where(lambda x: x <= outlier_cutoff).dropna().plot.hist(\n",
    "    title=f'Distribution of Prices\\nLess Than/Equal to ${outlier_cutoff}', ax=axes[2]);\n",
    "plt.savefig('price_histograms.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Question 1: How does geography influence Airbnb rental prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Add a choropleth (geographical map) and overlay the listings prices from the dataset.\n",
    "- Thank you for the geojson data: https://github.com/codeforgermany/click_that_hood/blob/main/public/data/boston.geojson?short_path=46589b4\n",
    "- Use log scale for the prices (so the colorbar isn't too compressed) - or change the scale of the colorbar.\n",
    "\n",
    "A quick visual inspection of the map allow us to see more expensive listings tend to northward, and in the following neighborhoods (in no particular order):\n",
    "- West End, North End, South End, Downtown, Leather District, Chinatown, Leather District, South Boston Waterfront, Fenway.\n",
    "\n",
    "- What if we run a regression-type model of price on latitude+longitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geoplot of neighborhoods with listings overlaid\n",
    "with open('./data/airbnb_boston/boston.geojson', 'r') as f:\n",
    "    geojson = json.load(f)\n",
    "    \n",
    "geoplot_data = boston_listings[['latitude', 'longitude', 'zipcode_cleaned', 'price']].dropna()\n",
    "geoplot_data['log_price'] = geoplot_data['price'].apply(np.log)\n",
    "\n",
    "fig = px.choropleth(\n",
    "    data_frame={'name': [i['properties']['name'] for i in geojson['features']]}, \n",
    "    geojson=geojson, \n",
    "    locations='name', \n",
    "    featureidkey=\"properties.name\",\n",
    "    title='Boston Neighborhoods and Airbnb Prices<br>Colorbar is Log Scale',\n",
    ")\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False) \n",
    "fig.add_trace(\n",
    "    px.scatter_geo(\n",
    "        data_frame=geoplot_data, \n",
    "        lat='latitude', \n",
    "        lon='longitude', \n",
    "        color='log_price',\n",
    "        hover_data={\n",
    "            'latitude': ':.2f', \n",
    "            'longitude': ':.2f', \n",
    "            'price': ':.2f', \n",
    "            'log_price': ':.2f',\n",
    "        },\n",
    "    ).data[0])\n",
    "\n",
    "# relabel the colorbar (as showing log values is confusing)\n",
    "fig.update_coloraxes(colorbar={\n",
    "    'title': 'Price',\n",
    "    'tickvals': geoplot_data['log_price'].quantile([0.01, 0.999]).values,\n",
    "    'ticktext': ['Cheaper', 'Pricier'],\n",
    "})\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, 'prices_and_neighborhoods.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_by_neighborhood = pd.concat([\n",
    "    boston_listings[['price', 'neighbourhood_cleansed']].groupby('neighbourhood_cleansed').mean().squeeze().to_frame('Mean Price'),\n",
    "    boston_listings[['price', 'neighbourhood_cleansed']].groupby('neighbourhood_cleansed').median().squeeze().to_frame('Median Price'),\n",
    "], axis=1).sort_values(by='Median Price', ascending=False)\n",
    "prices_by_neighborhood_styled = prices_by_neighborhood.style.format('${:.0f}').set_caption('Mean and Median Price by Neighborhood<br>Sorted by Median')\n",
    "dfi.export(prices_by_neighborhood_styled, 'prices_by_neighborhood_table.png')\n",
    "prices_by_neighborhood_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# What percentage of observations are below the outlier cutoff (say, below $500)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Percent of observations more than ${outlier_cutoff}: {\n",
    "    len(boston_listings['price'].where(lambda x: x > outlier_cutoff).dropna())/len(boston_listings):.1%\n",
    "    }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax = prices_by_neighborhood['Median Price'].plot.bar(cmap='viridis', title='Sorted Bar Plot of Median Price by Neighborhood')\n",
    "ax.axvline(11.5, color='black', alpha=0.2)\n",
    "ax.axhline(150, color='black', alpha=0.2)\n",
    "fig.tight_layout()\n",
    "plt.savefig('prices_by_prices_by_neighborhood_barplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Let's look at how well a regression can fit price on latitude and longitude\n",
    "- This gives a very poor fit, even on the training set. Why?\n",
    "    - It could be that latitude and longtide - which reflect locations on a sphere (the Earth) do not align well with 2d locations on a map.\n",
    "    - Therefore, the link betweeb price and lat/lon may not be linear, which means regression is not the right tool.\n",
    "    - Let's keep exploring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_price_on_lat_lon = estimate_y_from_X_ols(\n",
    "    data=boston_listings,\n",
    "    y_label='price',\n",
    "    X_labels=['latitude', 'longitude'],\n",
    "    train_size=0.6,\n",
    "    random_state=42,\n",
    "    add_constant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Question 2: How do characteristics influence Airbnb listing prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars_to_use = [\n",
    "    'bathrooms',               # number of bathrooms\n",
    "    'bedrooms',                # number of bedrooms\n",
    "    'beds',                    # number of beds\n",
    "    'accommodates',            # number of occupants that can be accomodated \n",
    "    'property_type',           # House, Apartment, Condoninium, etc\n",
    "    'room_type',               # Entire home/apt, Private room, Shared room\n",
    "    'cancellation_policy',     # moderate, flexible, strict, super_strict_30\n",
    "    'host_identity_verified',  # f, t (boolean)\n",
    "    'neighbourhood_cleansed',  # cleaned neighborhood label\n",
    "]\n",
    "\n",
    "numeric_features_to_use = [\n",
    "    'review_scores_accuracy',\n",
    "    'review_scores_cleanliness',\n",
    "    'review_scores_checkin',\n",
    "    'review_scores_communication',\n",
    "    'review_scores_location',\n",
    "    'review_scores_value',\n",
    "    'zipcode_cleaned'\n",
    "]\n",
    "\n",
    "grid = sns.pairplot(\n",
    "    data=boston_listings[['price'] + categorical_vars_to_use + numeric_features_to_use].dropna(),\n",
    ")\n",
    "grid.fig.suptitle('Pairplot of Price, Categorical Variables and Numerica Variables');\n",
    "grid.fig.tight_layout()\n",
    "grid.fig.savefig('variable_pairplot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_nan_details = pd.concat({\n",
    "    'NaN Count': boston_listings[['price'] + categorical_vars_to_use + numeric_features_to_use].isnull().sum(),\n",
    "    'NaN %': boston_listings[['price'] + categorical_vars_to_use + numeric_features_to_use].isnull().sum()/len(boston_listings),\n",
    "}, axis=1).rename_axis('Feature', axis=0).style.format('{:.1%}', subset='NaN %').set_caption('Missing Value Details for Selected Features')\n",
    "display(variable_nan_details)\n",
    "\n",
    "dfi.export(variable_nan_details, 'variable_nan_details.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Question 3: How does time influence Airbnb listing prices?\n",
    "- Day of week.\n",
    "- Week of month.\n",
    "- Month of year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert price column to a float, assuming format of $#.#\n",
    "boston_calendar.price = [float(i.replace('$', '').replace(',', '')) if type(i) is str else i for i in boston_calendar.price]\n",
    "\n",
    "# concert date to a datetime object\n",
    "boston_calendar.date = [pd.Timestamp(i) if type(i) is str else i for i in boston_calendar.date]\n",
    "\n",
    "# add a month, year columns for seasonality analysis\n",
    "day_map = {0: 'Mon', 1: 'Tues', 2: 'Wed', 3: 'Thurs', 4: 'Fri', 5: 'Sat', 6: 'Sun'}\n",
    "boston_calendar['weekday'] = [i.weekday() for i in boston_calendar.date]\n",
    "boston_calendar['month'] = [i.month for i in boston_calendar.date]\n",
    "boston_calendar['year'] = [i.year for i in boston_calendar.date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_data = boston_calendar.assign(log_price=lambda x: np.log(x['price'])).dropna()\n",
    "ax = sns.boxplot(\n",
    "    data=boxplot_data,\n",
    "    x='month',\n",
    "    y='log_price',\n",
    "    showfliers=False,\n",
    "    palette={month: 'salmon' if month in [9, 10, 11] else 'dodgerblue' for month in boxplot_data.month.unique()},\n",
    "    hue='month', legend=False,\n",
    ")\n",
    "ax.set_title(\"Distribution of Log Listing Prices by Calendar Month\");\n",
    "plt.savefig('price_by_month_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(\n",
    "    data=boxplot_data,\n",
    "    x='weekday',\n",
    "    y='log_price',\n",
    "    showfliers=False,\n",
    "    palette={weekday: 'salmon' if weekday in [4, 5] else 'dodgerblue' for weekday in boxplot_data.weekday.unique()},\n",
    "    hue='weekday', legend=False,\n",
    ")\n",
    "ax.set_title(\"Distribution of Log Listing Prices by Day of the Week\");\n",
    "ax.set_xticks(ax.get_xticks());\n",
    "ax.set_xticklabels(day_map[i] for i in ax.get_xticks());\n",
    "plt.savefig('price_by_weekday_boxplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "What other numerical values can we use (and what needs to be filled before we can)?\n",
    "- host_response_rate (missing around 400 entries)\n",
    "- host_acceptance_rate (missing around 400 entries)\n",
    "- square_feet (missing a lot)\n",
    "- extra people?\n",
    "- cleaning fee?\n",
    "- security_deposit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Assemble a model\n",
    "- Us a random forest regressor. This can handle both categorical and numeric values, and also can handle nans (especially in the numeric values, like the reviews, which contain numerous nans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = 'price'\n",
    "outlier_ids = list(boston_listings['price'].where(lambda x: x > outlier_cutoff).dropna().index)\n",
    "\n",
    "numeric_features_to_use = [\n",
    "    'review_scores_accuracy',\n",
    "    'review_scores_cleanliness',\n",
    "    'review_scores_checkin',\n",
    "    'review_scores_communication',\n",
    "    'review_scores_location',\n",
    "    'review_scores_value',\n",
    "    'zipcode_cleaned',\n",
    "]\n",
    "\n",
    "categorical_vars_to_use = [\n",
    "    'bathrooms',               # number of bathrooms\n",
    "    'bedrooms',                # number of bedrooms\n",
    "    'beds',                    # number of beds\n",
    "    'accommodates',            # number of occupants that can be accomodated \n",
    "    'property_type',           # House, Apartment, Condoninium, etc\n",
    "    'room_type',               # Entire home/apt, Private room, Shared room\n",
    "    'cancellation_policy',     # moderate, flexible, strict, super_strict_30\n",
    "    'host_identity_verified',  # f, t (boolean)\n",
    "    'neighbourhood_cleansed',  # cleaned neighborhood label\n",
    "]\n",
    "\n",
    "model_data = pd.concat([\n",
    "    boston_listings[[y_label]],\n",
    "    pd.get_dummies(boston_listings[categorical_vars_to_use], columns=categorical_vars_to_use, drop_first=True),\n",
    "    boston_listings[numeric_features_to_use],\n",
    "    ], axis=1).drop(outlier_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    model_data.drop(y_label, axis=1), \n",
    "    model_data[y_label],\n",
    "    train_size=0.6, \n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "m_rf = RandomForestRegressor(\n",
    "    random_state=42,\n",
    ")\n",
    "m_rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "scatter_data_train = pd.concat({\n",
    "        'Y_HAT': pd.Series(m_rf.predict(X_train)),\n",
    "        'Y_OBS': y_train.reset_index(drop=True),\n",
    "    }, axis=1)\n",
    "scatter_data_test = pd.concat({\n",
    "        'Y_HAT': pd.Series(m_rf.predict(X_test)),\n",
    "        'Y_OBS': y_test.reset_index(drop=True),\n",
    "    }, axis=1)\n",
    "\n",
    "sns.regplot(\n",
    "    data=scatter_data_train,\n",
    "    y='Y_HAT',\n",
    "    x='Y_OBS',\n",
    "    ax=axes[0],\n",
    "    ci=None,\n",
    "    line_kws={'color': 'dodgerblue'},\n",
    ")\n",
    "axes[0].set_title(f'Random Forest\\nTraining Data, Score: {m_rf.score(X_train, y_train):.2f}')\n",
    "\n",
    "sns.regplot(\n",
    "    data=scatter_data_test,\n",
    "    y='Y_HAT',\n",
    "    x='Y_OBS',\n",
    "    ax=axes[1],\n",
    "    ci=None,\n",
    "    line_kws={'color': 'dodgerblue'},\n",
    ")\n",
    "axes[1].set_title(f'Random Forest\\nTesting Data: Score: {m_rf.score(X_test, y_test):.2f}')\n",
    "fig.tight_layout()\n",
    "\n",
    "ymin = pd.concat([scatter_data_test, scatter_data_train], axis=0).min().min()\n",
    "ymax = pd.concat([scatter_data_test, scatter_data_train], axis=0).max().max()\n",
    "for i in axes:\n",
    "    ax.set_ylim((ymin, ymax))\n",
    "\n",
    "plt.savefig('model_train_test.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
