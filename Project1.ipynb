{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import plotly.express as px\n",
    "from math import radians # to convert latitude/longitude\n",
    "import dataframe_image as dfi\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Boston Airbnb Dataset\n",
    "https://www.kaggle.com/datasets/airbnb/boston?resource=download\n",
    "\n",
    "Three questions/topics to explore:\n",
    "- How does **geography** inlfuence Airbnb prices in Boston?\n",
    "    - What areas/zip codes/neighborhoods are more expensive than others?\n",
    "- How do **property characteristics** influence Airbnb prices in Boston?\n",
    "    - Number of bathrooms, bedrooms, beds, square footage, reviews, etc.\n",
    "- How does **time (seasonality)** influence Airbnb prices in Boston?\n",
    "    - Period of the week (days), period of the month (weeks), period of the year (months)?\n",
    "    - We only have about 2 years of data to work with, but we'll see what comes out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_and_types(df):\n",
    "    \"\"\"\n",
    "    Loop over the dtypes of the columns of a dataframe, and return a dictionary of lists identifying which are ints, floats and objects.\n",
    "    \"\"\"\n",
    "    print(f'Types detected: {\", \".join([str(i) for i in df.dtypes.unique()])}')\n",
    "    return {\n",
    "        'int': [label for label, dtype in df.dtypes.items() if dtype in [int, np.int64]],\n",
    "        'float': [label for label, dtype in df.dtypes.items() if dtype in [float, np.float64]],\n",
    "        'object': [label for label, dtype in df.dtypes.items() if dtype in ['O', 'object']],\n",
    "    }\n",
    "\n",
    "\n",
    "def convert_dollars_to_float(s, pattern=r\"\\$|,\"):\n",
    "    \"\"\"\n",
    "    Convert money-like strings to floats.\n",
    "    \"\"\"\n",
    "    if type(s) is str and re.match(pattern, s):\n",
    "        # if the input is a str containing '$' and/or ',' try to remove those chars and covert the result to a float\n",
    "        # if this fails, then there is likely text mixed in (like \"$195 this week only!\")\n",
    "        try:\n",
    "            return float(re.sub(pattern, repl='', string=s))\n",
    "        except:\n",
    "            return s\n",
    "    else:\n",
    "        # otherwise just return the input\n",
    "        return s\n",
    "\n",
    "\n",
    "def estimate_y_from_X(data, y_label, X_labels, train_size=0.6, random_state=42, add_constant=False):\n",
    "    \"\"\"\n",
    "    Run a linear regression on data using y_label as the dependent variable and X_labels as the independent variable(s): y_label ~ X_labels\n",
    "    A constant can be optionally added, but note that the r2 test may give misleading results when a constant is included.\n",
    "    \"\"\"\n",
    "    if type(X_labels) not in [list, tuple]:\n",
    "        X_labels = [X_labels] # in case we pass a scalar\n",
    "        \n",
    "    # we know that we have data for 'price' in all observations, but not for 'monthly_price' or 'weekly_price'\n",
    "    # drop the nans, create a train/test split, build a model and estimate the monthly, then use the model to fill the missing values in the dataset\n",
    "    reg_data = data[X_labels + [y_label]].dropna()\n",
    "    y = reg_data[y_label]\n",
    "    X = reg_data[X_labels]\n",
    "    if add_constant:\n",
    "        X = sm.add_constant(reg_data[X_labels])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=random_state)\n",
    "\n",
    "    print(f'Estimating {y_label}~1+{\"+\".join(X_labels)}')\n",
    "    m = sm.OLS(exog=X_train, endog=y_train).fit()\n",
    "    \n",
    "    print(f'... Train fit: {r2_score(y_true=y_train, y_pred=m.predict(exog=X_train)):.2f}')\n",
    "    print(f'... Test fit: {r2_score(y_true=y_test, y_pred=m.predict(exog=X_test)):.2f}')\n",
    "    \n",
    "    print(f'... Filling NaNs in {y_label} with estimated data')\n",
    "    missing = data[y_label][data[y_label].isnull()].index\n",
    "    if add_constant:\n",
    "        data.loc[missing, y_label] = m.predict(exog=sm.add_constant(data[data[y_label].isnull()][X_labels]))\n",
    "    else:\n",
    "        data.loc[missing, y_label] = m.predict(exog=data[data[y_label].isnull()][X_labels])\n",
    "    \n",
    "    return {\n",
    "        'filled_data': data,\n",
    "        'model': m,\n",
    "        'X_train': X_train, \n",
    "        'X_test': X_test, \n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "    }\n",
    "\n",
    "\n",
    "def convert_percentages_to_float(s):\n",
    "    \"\"\"\n",
    "    Take in a value, and if it is a string ending with a percent side, strip the percent sign and return a float. \n",
    "    If the conversion fails, return the original value.\n",
    "    \"\"\"\n",
    "    if type(s) is str and s.endswith('%'):\n",
    "        try:\n",
    "            return float(s.strip('%'))\n",
    "        except:\n",
    "            return s\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def convert_string_date_to_dt(s):\n",
    "    \"\"\"\n",
    "    Take in a value, and if it is a string that looks like a date in YYYY-MM-DD format, convert it to a datetime object.\n",
    "    If the conversion fails, return the original value.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return dt.strptime(s, '%Y-%m-%d')\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "        \n",
    "def get_cleaned_zipcodes(data):\n",
    "    \"\"\"\n",
    "    Scan over the values of 'zipcodes' in the data, and isolate those that are 5 characters long, with other values\n",
    "    return as NaN. This dataset is pretty clean with zips, but there's at least 1 entry where the zip is more than 10 digits.\n",
    "    Store the cleaned values as 'zipcode_cleaned'. Note that if the 'zipcode_cleaned' field is aready in data, it will be dropped \n",
    "    and recalculated.\n",
    "\n",
    "    The 'zipcode_cleaned' field - including the nans - will be used later to feed into a classifier (to get estimates for the nans \n",
    "    based on latitude and longitude).\n",
    "    \"\"\"\n",
    "    if 'zipcode_cleaned' in data:\n",
    "        data = data.drop('zipcode_cleaned', axis=1)\n",
    "\n",
    "    new_zipcodes = []\n",
    "    for k, v in data['zipcode'].items():\n",
    "        if pd.isnull(v) or type(v) is str and len(v) != 5:\n",
    "            new_zipcodes.append(np.nan)\n",
    "        else:\n",
    "            new_zipcodes.append(str(v))\n",
    "    data = pd.concat([\n",
    "        data,\n",
    "        pd.Series(index=data.index, data=new_zipcodes).to_frame('zipcode_cleaned').astype('Int64'),\n",
    "    ], axis=1)\n",
    "    return data\n",
    "    \n",
    "\n",
    "def classify_y_based_on_X(data, y_label, X_labels, train_size=0.6, random_state=42):\n",
    "    \"\"\"\n",
    "    Wrapped for a K nearest neighbor classifier, that will estimate categories contained in y_label column of data, \n",
    "    using the variables contained in X labels columns of data.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(X_labels) is str:\n",
    "        X_labels = [X_labels]\n",
    "    \n",
    "    knn_data = data[[y_label] + X_labels].dropna()\n",
    "    y = knn_data[y_label]\n",
    "    X = knn_data[X_labels]    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=random_state)\n",
    "    \n",
    "    print(f'Estimating {y_label} labels from {\"+\".join(X_labels)}')\n",
    "    m_knn = KNeighborsClassifier()\n",
    "    m_knn.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'... Train fit: {m_knn.score(X_train, y_train):.2f}')\n",
    "    print(f'... Test fit: {m_knn.score(X_test, y_test):.2f}')\n",
    "    \n",
    "    print(f'... Filling NaNs in {y_label} with estimated data')\n",
    "    missing = data[y_label][data[y_label].isnull()].index\n",
    "    data.loc[missing, y_label] = m_knn.predict(data[data[y_label].isnull()][X_labels])\n",
    "    \n",
    "    return {\n",
    "        'filled_data': data,\n",
    "        'model': m_knn,\n",
    "        'X_train': X_train, \n",
    "        'X_test': X_test, \n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# First, load and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listings = pd.read_csv('./data/airbnb_boston/listings.csv', index_col='id')\n",
    "boston_calendar = pd.read_csv('./data/airbnb_boston/calendar.csv')\n",
    "boston_reviews = pd.read_csv('./data/airbnb_boston/reviews.csv')\n",
    "\n",
    "boston_listings = boston_listings.map(convert_dollars_to_float).map(convert_percentages_to_float).map(convert_string_date_to_dt)\n",
    "boston_calendar = boston_calendar.apply(convert_dollars_to_float).map(convert_percentages_to_float).map(convert_string_date_to_dt)\n",
    "boston_reviews = boston_reviews.apply(convert_dollars_to_float).map(convert_percentages_to_float).map(convert_string_date_to_dt)\n",
    "\n",
    "# estimate missing monthly_price/weekly_price fields using regression (based on price field)\n",
    "boston_listings = estimate_y_from_X(data=boston_listings, y_label='monthly_price', X_labels='price')['filled_data']\n",
    "boston_listings = estimate_y_from_X(data=boston_listings, y_label='weekly_price', X_labels='price')['filled_data']\n",
    "\n",
    "# estimate missing zip codes using KNN classification (based on latitude and longitude)\n",
    "boston_listings = classify_y_based_on_X(\n",
    "    data=get_cleaned_zipcodes(boston_listings), y_label='zipcode_cleaned', X_labels=['latitude', 'longitude'])['filled_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify column types\n",
    "boston_listing_col_types = get_columns_and_types(boston_listings)\n",
    "boston_calendar_col_types = get_columns_and_types(boston_calendar)\n",
    "boston_review_col_types = get_columns_and_types(boston_reviews)\n",
    "# boston_listing_col_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Question 1: How does geography influence Airbnb rental prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Add a choropleth (geographical map) and overlay the listings prices from the dataset.\n",
    "- Thank you for the geojson data: https://github.com/codeforgermany/click_that_hood/blob/main/public/data/boston.geojson?short_path=46589b4\n",
    "- Use log scale for the prices (so the colorbar isn't too compressed) - or change the scale of the colorbar.\n",
    "\n",
    "A quick visual inspection of the map allow us to see more expensive listings tend to northward, and in the following neighborhoods (in no particular order):\n",
    "- West End, North End, South End, Downtown, Leather District, Chinatown, Leather District, South Boston Waterfront, Fenway.\n",
    "\n",
    "- What if we run a regression-type model of price on latitude+longitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geoplot of neighborhoods with listings overlaid\n",
    "with open('./data/airbnb_boston/boston.geojson', 'r') as f:\n",
    "    geojson = json.load(f)\n",
    "    \n",
    "geoplot_data = boston_listings[['latitude', 'longitude', 'zipcode_cleaned', 'price']].dropna()\n",
    "geoplot_data['log_price'] = geoplot_data['price'].apply(np.log)\n",
    "\n",
    "fig = px.choropleth(\n",
    "    data_frame={'name': [i['properties']['name'] for i in geojson['features']]}, \n",
    "    geojson=geojson, \n",
    "    locations='name', \n",
    "    featureidkey=\"properties.name\",\n",
    "    title='Boston Neighborhoods and Airbnb Prices<br>Colorbar is Log Scale',\n",
    ")\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False) \n",
    "fig.add_trace(\n",
    "    px.scatter_geo(\n",
    "        data_frame=geoplot_data, \n",
    "        lat='latitude', \n",
    "        lon='longitude', \n",
    "        color='log_price',\n",
    "        hover_data={\n",
    "            'latitude': ':.2f', \n",
    "            'longitude': ':.2f', \n",
    "            'price': ':.2f', \n",
    "            'log_price': ':.2f',\n",
    "        },\n",
    "    ).data[0])\n",
    "\n",
    "# relabel the colorbar (as showing log values is confusing)\n",
    "fig.update_coloraxes(colorbar={\n",
    "    'title': 'Price',\n",
    "    'tickvals': geoplot_data['log_price'].quantile([0.01, 0.999]).values,\n",
    "    'ticktext': ['Cheaper', 'Pricier'],\n",
    "})\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, 'prices_and_neighborhoods.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_by_neighborhood = pd.concat([\n",
    "    boston_listings[['price', 'neighbourhood_cleansed']].groupby('neighbourhood_cleansed').mean().squeeze().to_frame('Mean Price'),\n",
    "    boston_listings[['price', 'neighbourhood_cleansed']].groupby('neighbourhood_cleansed').median().squeeze().to_frame('Median Price'),\n",
    "], axis=1).sort_values(by='Median Price', ascending=False)\n",
    "prices_by_neighborhood_styled = prices_by_neighborhood.style.format('${:.0f}').set_caption('Mean and Median Price by Neighborhood<br>Sorted by Median')\n",
    "dfi.export(prices_by_neighborhood_styled, 'prices_by_neighborhood_table.png')\n",
    "prices_by_neighborhood_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax = prices_by_neighborhood['Median Price'].plot.bar(cmap='viridis', title='Sorted Bar Plot of Median Price by Neighborhood')\n",
    "ax.axvline(11.5, color='black', alpha=0.2)\n",
    "ax.axhline(150, color='black', alpha=0.2)\n",
    "fig.tight_layout()\n",
    "plt.savefig('prices_by_prices_by_neighborhood_barplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Let's look at how well a regression can fit price on latitude and longitude\n",
    "- This gives a very poor fit, even on the training set. Why?\n",
    "    - It could be that latitude and longtide - which reflect locations on a sphere (the Earth) do not align well with 2d locations on a map.\n",
    "    - Therefore, the link betweeb price and lat/lon may not be linear, which means regression is not the right tool.\n",
    "    - Let's keep exploring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_price_on_lat_lon = estimate_y_from_X(\n",
    "    data=boston_listings,\n",
    "    y_label='price',\n",
    "    X_labels=['latitude', 'longitude'],\n",
    "    train_size=0.6,\n",
    "    random_state=42,\n",
    "    add_constant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=pd.concat({\n",
    "        'y_train': reg_price_on_lat_lon['y_train'],\n",
    "        'y_fitted': reg_price_on_lat_lon['model'].fittedvalues,\n",
    "    }, axis=1),\n",
    "    x='y_train',\n",
    "    y='y_fitted',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Question 2: How do characteristics influence Airbnb listing prices?\n",
    "- Here, we can structure a regression on categorical variables against price.\n",
    "    - But we should ensure that numeric categoricals - like number of bedrooms - appear here!\n",
    "    - Quantitative variables - like square footage - should also appear!\n",
    "- Remember to create dummies from the categoricals.\n",
    "- From a manual review of categories, these look like they may be informative (not free text, not arbitrary values, etc)\n",
    "    - room_type\n",
    "- TODO: clean up AMENITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listings['room_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listing_col_types['int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = [\n",
    "    'name', 'summary', 'space', 'description', 'neighborhood_overview', 'host_verifications', 'neighbourhood', 'host_about', 'notes',\n",
    "    'transit', 'host_location', 'access', 'host_about', 'interaction', 'zipcode', 'smart_location', 'house_rules',\n",
    "    'neighbourhood_cleansed', 'city', 'street', 'host_neighbourhood', 'host_name',\n",
    "]\n",
    "\n",
    "unique_characteristics = {}\n",
    "for i in boston_listing_col_types['object'] + boston_listing_col_types['int']:\n",
    "    if i in ignore or '_url' in i:\n",
    "        continue\n",
    "    unique_values = boston_listings[i].dropna().unique()\n",
    "    if len(unique_values) > 1:\n",
    "        unique_characteristics[i] = unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listing_col_types['float']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    data=boston_listings[['price', 'bathrooms', 'bedrooms', 'beds', 'square_feet']].dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=boston_listings[['price', 'square_feet']].dropna(),\n",
    "    x='square_feet', y='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listings[boston_listing_col_types['object']].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(\n",
    "#     boston_listings[boston_listing_col_types['float']].sort_index().dropna(how='all', axis=1) \\\n",
    "#         .drop(['latitude', 'longitude', 'weekly_price', 'monthly_price'], axis=1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Question 3: How does time influence Airbnb listing prices?\n",
    "- Day of week.\n",
    "- Week of month.\n",
    "- Month of year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert price column to a float, assuming format of $#.#\n",
    "boston_calendar.price = [float(i.replace('$', '').replace(',', '')) if type(i) is str else i for i in boston_calendar.price]\n",
    "\n",
    "# concert date to a datetime object\n",
    "boston_calendar.date = [pd.Timestamp(i) if type(i) is str else i for i in boston_calendar.date]\n",
    "\n",
    "# add a month, year columns for seasonality analysis\n",
    "day_map = {0: 'Mon', 1: 'Tues', 2: 'Wed', 3: 'Thurs', 4: 'Fri', 5: 'Sat', 6: 'Sun'}\n",
    "boston_calendar['weekday'] = [i.weekday() for i in boston_calendar.date]\n",
    "boston_calendar['month'] = [i.month for i in boston_calendar.date]\n",
    "boston_calendar['year'] = [i.year for i in boston_calendar.date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_data = boston_calendar.assign(log_price=lambda x: np.log(x['price'])).dropna()\n",
    "ax = sns.boxplot(\n",
    "    data=boxplot_data,\n",
    "    x='month',\n",
    "    y='log_price',\n",
    "    showfliers=False,\n",
    "    palette={month: 'salmon' if month in [9, 10, 11] else 'dodgerblue' for month in boxplot_data.month.unique()},\n",
    "    hue='month', legend=False,\n",
    ")\n",
    "ax.set_title(\"Distribution of Log Listing Prices by Calendar Month\");\n",
    "plt.savefig('price_by_month_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(\n",
    "    data=boxplot_data,\n",
    "    x='weekday',\n",
    "    y='log_price',\n",
    "    showfliers=False,\n",
    "    palette={weekday: 'salmon' if weekday in [4, 5] else 'dodgerblue' for weekday in boxplot_data.weekday.unique()},\n",
    "    hue='weekday', legend=False,\n",
    ")\n",
    "ax.set_title(\"Distribution of Log Listing Prices by Day of the Week\");\n",
    "ax.set_xticks(ax.get_xticks());\n",
    "ax.set_xticklabels(day_map[i] for i in ax.get_xticks());\n",
    "plt.savefig('price_by_weekday_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
